---
title: Táº¡o chatbot "like ChatGPT" miá»…n phÃ­ vá»›i Ollama vÃ  Open WebUI
layout: post
post-image: "https://images.viblo.asia/100x100/38326b12-21d0-4a55-b299-70c29eca1c2c.png"
description: HÆ°á»›ng dáº«n táº¡o chatbot
tags:
- sample
- post
- test
---

# Giá»›i thiá»‡u
Sá»± máº¡nh máº½ cá»§a ChatGPT Ä‘Æ°a báº¡n Ä‘áº¿n vá»›i viá»‡c nghiÃªn cá»©u vá» cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n (LLMs) vÃ  muá»‘n dá»±ng má»™t app chatbot giá»‘ng nhÆ° ChatGPT? Báº¡n muá»‘n táº¡o ra má»™t chatbot mang dáº¥u áº¥n cÃ¡ nhÃ¢n? Báº¡n muá»‘n triá»ƒn khai má»™t cÃ´ng cá»¥ chatbot cho nhÃ³m cá»§a báº¡n á»Ÿ cÃ´ng ty phá»¥c vá»¥ cÃ¡c cÃ´ng viá»‡c hÃ ng ngÃ y? BÃ i viáº¿t nÃ y sáº½ hÆ°á»›ng dáº«n cÃ¡c báº¡n cÃ³ thá»ƒ xÃ¢y dá»±ng má»™t chatbot miá»…n phÃ­ (Ä‘áº¥y lÃ  khi báº¡n cÃ³ sáºµn GPU rá»“i ğŸ¤­) Ä‘á»ƒ thuáº­n tiá»‡n hÆ¡n cho viá»‡c nghiÃªn cá»©u cÅ©ng nhÆ° cÃ³ thá»ƒ Ä‘Ã¡p á»©ng tÆ°Æ¡ng Ä‘á»‘i cÃ¡c tÃ­nh nÄƒng giá»‘ng nhÆ° ChatGPT (cÃ¡i nÃ y cÃ²n tÃ¹y vÃ o tÃ i nguyÃªn pháº§n cá»©ng báº¡n cÃ³ nha ğŸ«¢). Let's go 

# Cháº¡y LLMs vá»›i Ollama
Cháº¡y cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n (LLMs) trÃªn local server cÃ³ thá»ƒ ráº¥t há»¯u Ã­ch khi báº¡n cÃ³ sáºµn tÃ i nguyÃªn tÃ­nh toÃ¡n, dÃ¹ báº¡n muá»‘n khÃ¡m phÃ¡ vá»›i LLMs hay xÃ¢y dá»±ng cÃ¡c á»©ng dá»¥ng máº¡nh máº½ hÆ¡n báº±ng chÃºng. Tuy nhiÃªn, viá»‡c cáº¥u hÃ¬nh mÃ´i trÆ°á»ng lÃ m viá»‡c vÃ  cháº¡y LLMs trÃªn mÃ¡y cá»§a báº¡n khÃ´ng pháº£i lÃ  viá»‡c dá»… dÃ ng do cÃ³ nhiá»u váº¥n Ä‘á» vá» tá»‘i Æ°u. Vá»›i viá»‡c sá»­ dá»¥ng Ollama, báº¡n cÃ³ thá»ƒ dá»… dÃ ng cÃ³ thá»ƒ cháº¡y Ä‘Æ°á»£c mÃ´ hÃ¬nh Llama 3.1 (q4_0 quantization) vá»›i GPU khoáº£ng 8GB VRAM.

Váº­y lÃ m tháº¿ nÃ o Ä‘á»ƒ cháº¡y LLMs trÃªn local server nhanh chÃ³ng? HÃ£y Ä‘áº¿n vá»›i Ollama, má»™t ná»n táº£ng giÃºp phÃ¡t triá»ƒn cá»¥c bá»™ vá»›i cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n mÃ£ nguá»“n má»Ÿ trá»Ÿ nÃªn Ä‘Æ¡n giáº£n. Vá»›i Ollama, má»i thá»© báº¡n cáº§n Ä‘á»ƒ cháº¡y má»™t LLM lÃ  weight cá»§a mÃ´ hÃ¬nh vÃ  táº¥t cáº£ cÃ¡c cáº¥u hÃ¬nh Ä‘á»u Ä‘Æ°á»£c Ä‘Ã³ng gÃ³i vÃ o má»™t file Modelfile duy nháº¥t. HÃ£y tÆ°á»Ÿng tÆ°á»£ng cÃ¡ch hoáº¡t Ä‘á»™ng cá»§a Docker cho LLMs.
Trong pháº§n nÃ y, chÃºng ta sáº½ tÃ¬m hiá»ƒu cÃ¡ch báº¯t Ä‘áº§u vá»›i Ollama Ä‘á»ƒ cháº¡y cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n trÃªn server local. HÆ°á»›ng dáº«n nÃ y Ä‘Æ°á»£c thá»±c hiá»‡n trÃªn há»‡ Ä‘iá»u hÃ nh Ubuntu. Vá»›i Windows hay Mac, cÃ¡c báº¡n cÃ³ thá»ƒ tÃ¬m Ä‘á»c docs cá»§a Ollama vÃ  Open WebUI nÃ³ cÅ©ng khÃ¡ dá»… náº¯m báº¯t

## CÃ i Ä‘áº·t Ollama
BÆ°á»›c Ä‘áº§u tiÃªn, báº¡n cáº§n táº£i Ollama vá» mÃ¡y cá»§a mÃ¬nh. Ollama há»— trá»£ trÃªn táº¥t cáº£ cÃ¡c ná»n táº£ng chÃ­nh: MacOS, Windows vÃ  Linux.

Äá»ƒ táº£i Ollama, báº¡n cÃ³ thá»ƒ truy cáº­p [GitHub repo](https://github.com/ollama/ollama) vÃ  lÃ m theo cÃ¡c hÆ°á»›ng dáº«n. Hoáº·c truy cáº­p trang web chÃ­nh thá»©c cá»§a [Ollama](https://ollama.com/) Ä‘á»ƒ cÃ i Ä‘áº·t
TrÃªn Ubuntu, mÃ¬nh sá»­ dá»¥ng lá»‡nh sau Ä‘á»ƒ cÃ i Ä‘áº·t:
```
curl -fsSL https://ollama.com/install.sh | sh
```
QuÃ¡ trÃ¬nh cÃ i Ä‘áº·t thÆ°á»ng máº¥t vÃ i phÃºt. Trong quÃ¡ trÃ¬nh cÃ i Ä‘áº·t, driver cá»§a GPU NVIDIA/AMD sáº½ Ä‘Æ°á»£c phÃ¡t hiá»‡n tá»± Ä‘á»™ng (HÃ£y cháº¯c cháº¯n ráº±ng báº¡n Ä‘Ã£ cÃ i Ä‘áº·t driver). Ollama cÅ©ng cÃ³ thá»ƒ chá»‰ sá»­ dá»¥ng CPU khi khÃ´ng Ä‘á»§ GPU cáº§n thiáº¿t cho model (nhÆ°ng cháº¯c khÃ´ng ai muá»‘n má»™t con chatbot cháº­m rÃ¬ vÃ i phÃºt má»›i rep xong 1 cÃ¢u Ä‘Æ¡n giáº£n Ä‘Ã¢u ğŸ™ƒ)

## KÃ©o model vá» vÃ  cháº¡y
Tiáº¿p theo, báº¡n cÃ³ thá»ƒ truy cáº­p [thÆ° viá»‡n mÃ´ hÃ¬nh cá»§a Ollama](https://ollama.com/library) Ä‘á»ƒ kiá»ƒm tra danh sÃ¡ch táº¥t cáº£ cÃ¡c há» mÃ´ hÃ¬nh hiá»‡n Ä‘ang Ä‘Æ°á»£c há»— trá»£ (Ä‘áº¿n thá»i Ä‘iá»ƒm mÃ¬nh viáº¿t bÃ i nÃ y, Ollama Ä‘Ã£ há»— trá»£ Ä‘áº¿n Llama 3.2 1B vÃ  3B, chÆ°a há»— trá»£ báº£n vision 11B vÃ  90B). MÃ´ hÃ¬nh máº·c Ä‘á»‹nh Ä‘Æ°á»£c táº£i xuá»‘ng lÃ  mÃ´ hÃ¬nh cÃ³ tag `latest` (tháº¥y nÃ³ báº¯t Ä‘áº§u giá»‘ng Docker rá»“i ha ğŸ¤—). TrÃªn trang cá»§a tá»«ng mÃ´ hÃ¬nh, báº¡n cÃ³ thá»ƒ tÃ¬m thÃªm thÃ´ng tin nhÆ° kÃ­ch thÆ°á»›c vÃ  phÆ°Æ¡ng phÃ¡p lÆ°á»£ng tá»­ hÃ³a (quantization) Ä‘Æ°á»£c sá»­ dá»¥ng. Quantization hiá»ƒu Ä‘Æ¡n giáº£n lÃ  sáº½ cÆ°a bá»›t pháº§n tháº­p phÃ¢n cá»§a má»—i params Ä‘á»ƒ tá»‘n Ã­t bá»™ nhá»› lÆ°u trá»¯ hÆ¡n vÃ  Ä‘Ã¡nh Ä‘á»•i lÃ  Ä‘á»™ chÃ­nh xÃ¡c sáº½ kÃ©m Ä‘i (Do thá»i lÆ°á»£ng bÃ i viáº¿t cÃ³ háº¡n mÃ¬nh khÃ´ng Ä‘i sÃ¢u váº¥n Ä‘á» nÃ y). Máº·c Ä‘á»‹nh full precision cho sá»‘ tháº­p phÃ¢n lÃ  32bits (FP32). Tuy nhiÃªn theo tráº£i nghiá»‡m cÃ¡ nhÃ¢n mÃ¬nh thÃ¬ cÃ¡c mÃ´ hÃ¬nh máº·c Ä‘á»‹nh cá»§a Ollama thÆ°á»ng Ä‘Æ°á»£c quantize vá» 4bit vÃ  váº«n Ä‘Ã¡p á»©ng tá»‘t cÃ¡c tÃ¡c vá»¥ thÃ´ng thÆ°á»ng nhÆ° code hoáº·c Ä‘á»c hiá»ƒu vÄƒn báº£n.
TrÃªn thÆ° viá»‡n cá»§a Ollama, báº¡n cÃ³ thá»ƒ xem cÃ¡c biá»ƒn thá»ƒ model vÃ  sá»‘ lÆ°á»£ng tham sá»‘ cá»§a chÃºng Ä‘á»ƒ cÃ³ thá»ƒ lá»±a chá»n model phÃ¹ há»£p vá»›i nhu cáº§u sá»­ dá»¥ng

<div align="center">
  <img src="https://images.viblo.asia/038918e9-366a-4344-b6dd-f570e1dfbb5d.png" alt="image.png" />
  ThÆ° viá»‡n mÃ´ hÃ¬nh Ollama
</div>

Báº¡n cÃ³ thá»ƒ cháº¡y mÃ´ hÃ¬nh báº±ng lá»‡nh `ollama run` Ä‘á»ƒ táº£i vá» vÃ  báº¯t Ä‘áº§u tÆ°Æ¡ng tÃ¡c vá»›i mÃ´ hÃ¬nh trá»±c tiáº¿p. Tuy nhiÃªn, báº¡n cÅ©ng cÃ³ thá»ƒ kÃ©o (pull) mÃ´ hÃ¬nh vá» mÃ¡y trÆ°á»›c vÃ  sau Ä‘Ã³ má»›i cháº¡y. Äiá»u nÃ y tÆ°Æ¡ng tá»± nhÆ° cÃ¡ch báº¡n lÃ m viá»‡c vá»›i cÃ¡c Docker image.

VÃ­ dá»¥ Ä‘á»ƒ táº£i xuá»‘ng mÃ´ hÃ¬nh `Llama 3.1`, hÃ£y cháº¡y lá»‡nh terminal Ä‘á»ƒ:
```
ollama pull llama3.1
```
Hoáº·c cháº¡y luÃ´n nhÆ° nÃ y
```
ollama run llama3.1
```
Náº¿u mÃ´ hÃ¬nh chÆ°a cÃ³ thÃ¬ Ollama sáº½ tá»± pull vá». Sau khi cháº¡y báº¡n cÃ³ thá»ƒ chat trá»±c tiáº¿p vá»›i Ollama trÃªn Terminal (Ä‘á»ƒ thoÃ¡t báº¡n cÃ³ thá»ƒ gÃµ `/bye` hoáº·c nháº¥n `Ctrl+D`

## Customize mÃ´ hÃ¬nh
Láº¡i giá»‘ng nhÆ° Docker, báº¡n cÃ³ thá»ƒ chá»‰nh sá»­a mÃ´ hÃ¬nh vá»›i viá»‡c viáº¿t `Modelfile`. VÃ­ dá»¥ vá» viá»‡c thÃªm system prompt báº¡n cÃ³ thá»ƒ tham kháº£o máº«u sau
```
FROM llama3.1:latest

SYSTEM """
You are a virtual assistant developed by the AI Team of TonAI Company
Your name is 'TonAI Láº¡c ÄÃ ' (Llama is Láº¡c Ä‘Ã  in Vietnamese) because your base model is Llama 3.1 8B
"""
```
NgoÃ i ra báº¡n cÃ³ thá»ƒ chá»‰nh sá»­a cÃ¡c tham sá»‘ cá»§a mÃ´ hÃ¬nh nhÆ° `temperature`, `num_ctx`... CÃ¡ch viáº¿t Modeilfile chi tiáº¿t báº¡n cÃ³ thá»ƒ tham kháº£o táº¡i [link](https://www.gpu-mart.com/blog/custom-llm-models-with-ollama-modelfile) nÃ y hoáº·c tÃ¬m kiáº¿m trÃªn [Ollama Hub](https://openwebui.com/), Ä‘Ã¢y lÃ  nÆ¡i má»i ngÆ°á»i chia sáº» vá» cÃ¡c mÃ´ hÃ¬nh.
Äá»ƒ táº¡o mÃ´ hÃ¬nh mÆ¡i, báº¡n cháº¡y lá»‡nh

```
ollama create TonAI:chatbot_mini -f ./Modelfile
```
Trong Ä‘Ã³ `TonAI:chatbot_mini` lÃ  tÃªn model cá»§a mÃ¬nh (náº¿u cÃ¡c báº¡n khÃ´ng viáº¿t gÃ¬ sau dáº¥u `:` nÃ³ sáº½ auto lÃ  `latest` nhÆ° Docker) vÃ  `f [Ä‘Æ°á»ng dáº«n tá»›i Modelfile]`
Sau khi táº¡o model ta cÃ³ thá»ƒ cháº¡y thá»­ nghiá»‡m
```
ollama run TonAI:chatbot_mini
```
VÃ  sau Ä‘Ã¢y lÃ  káº¿t quáº£
```
>>> Hi
Xin chÃ o! (Hello!) How can I assist you today? Is there something specific on your mind, or would you like to have a chat?

>>> Who are you
I am TonAI Láº¡c ÄÃ , a virtual assistant developed by the AI Team of TonAI Company. My base model is based on Llama 3.1 8B, which allows me to understand and respond to a wide 
range of questions and topics.

I'm here to help answer your questions, provide information, offer suggestions, and even just have a friendly conversation if you'd like!

>>> Send a message (/? for help)
```
## Sá»­ dá»¥ng Ollama vá»›i Python
NgoÃ i ra báº¡n cÃ³ thá»ƒ sá»­ dá»¥ng Ollama vá»›i thÆ° viá»‡n python. CÃ i Ä‘áº·t Ollama báº±ng cÃ¡ch sá»­ dá»¥ng `pip`:
```
$ pip install ollama
```
DÆ°á»›i Ä‘Ã¢y lÃ  má»™t vÃ­ dá»¥ sá»­ dá»¥ng Ollama vá»›i Python
```
import ollama

while True:
    message = input("User: ")
    response = ollama.chat(model='TonAI:chatbot_mini', messages=[
        {
            'role': 'user',
            'content': message,
        },
    ])
    print(f"Ollama: {response['message']['content']}")
 ```

# Open WebUI
sau khi cÃ i Ollama, báº¡n cáº§n má»™t giao diá»‡n Ä‘á»ƒ sá»­ dá»¥ng dá»… dÃ ng hÆ¡n. á» trong bÃ i nÃ y mÃ¬nh sáº½ sá»­ dá»¥ng Open WebUI Ä‘á»ƒ dá»±ng má»™t giao diá»‡n web giá»‘ng ChatGPT.
> Open WebUI is an extensible, feature-rich, and user-friendly self-hosted WebUI designed to operate entirely offline. It supports various LLM runners, including Ollama and OpenAI-compatible APIs.

Báº¡n cÃ³ thá»ƒ cÃ i Ä‘áº·t Open WebUI báº±ng cÃ¡ch sá»­ dá»¥ng Docker, PyPi hoáº·c cÃ³ thá»ƒ kÃ©o source code táº¡i [ÄÃ‚Y](https://github.com/open-webui/open-webui)
## CÃ i Ä‘áº·t
### Vá»›i Docker:
Náº¿u sá»­ dá»¥ng GPU, cháº¡y cÃ¢u lá»‡nh sau:
```
$ docker run -d -p 3000:8080 --gpus=all -v ollama:/root/.ollama -v open-webui:/app/backend/data --name open-webui --restart always ghcr.io/open-webui/open-webui:ollama
```
Vá»›i báº¡n nÃ o chá»‰ dÃ¹ng CPU:
```
$ docker run -d -p 3000:8080 -v ollama:/root/.ollama -v open-webui:/app/backend/data --name open-webui --restart always ghcr.io/open-webui/open-webui:ollama
```
Sau khi cÃ i Ä‘áº·t, báº¡n cÃ³ thá»ƒ truy cáº­p Open WebUI táº¡i Ä‘á»‹a chá»‰ `http://localhost:3000`
### Vá»›i Python pip:
Cháº¡y lá»‡nh sau Ä‘á»ƒ cÃ i Ä‘áº·t Open WebUI:
```
$ pip install open-webui
```
Cháº¡y lá»‡nh sau Ä‘á»ƒ cháº¡y Open WebUI
```
$ open-webui serve
```
Sau khi cÃ i Ä‘áº·t, báº¡n cÃ³ thá»ƒ truy cáº­p Open WebUI táº¡i Ä‘á»‹a chá»‰ `http://localhost:8080`

### Vá»›i Source code:
CÃ¡ch nÃ y khÃ¡ há»¯u Ã­ch khi báº¡n cÃ³ thá»ƒ customize giao diá»‡n theo Ã½ mÃ¬nh. Äáº§u tiÃªn clone source code vá» mÃ¡y:
```
$ git clone https://github.com/open-webui/open-webui.git
```
Trong thÆ° má»¥c `backend` cÃ³ má»™t file script `start.sh`, cÃ¡c báº¡n cÃ³ thá»ƒ cháº¡y nÃ³ (trong Ä‘Ã³ cÃ³ thá»ƒ customize port vÃ  hostname)
```
$ cd open-webui/backend
$ bash start.sh
```
Äá»ƒ trÃ¡nh trÆ°á»ng há»£p khi báº¡n táº¯t Terminal, á»©ng dá»¥ng sáº½ bá»‹ down thÃ¬ cÃ³ thá»ƒ tham kháº£o [cÃ¡ch sá»­ dá»¥ng Tmux](https://viblo.asia/p/toi-uu-hoa-tmux-trong-lap-trinh-zXRJ8DQ5JGq) Ä‘á»ƒ treo á»©ng dá»¥ng nÃ y liÃªn tá»¥c

## Tráº£i nghiá»‡m thÃ´i nÃ o ğŸ˜

<div align="center">
  <img src="https://images.viblo.asia/d088e487-1846-428f-aa6f-724d1fb44b50.png" alt="image.png" />

  Customize model tráº£ lá»i theo Ã½ báº¡n
</div>


<div align="center">
  <img src="https://images.viblo.asia/b144d940-4441-4471-a33a-bb1ef221cd7f.png" alt="image.png" />
  
  Ollama cÃ³ thá»ƒ truy cáº­p link, tÃ i liá»‡u Ä‘á»ƒ Ä‘á»c. 
</div>

Ollama cÃ³ thá»ƒ truy cáº­p link, tÃ i liá»‡u Ä‘á»ƒ Ä‘á»c. Vá»›i má»™t sá»‘ mÃ´ hÃ¬nh vision cÃ³ thá»ƒ nháº­n diá»‡n Ä‘Æ°á»£c áº£nh input.
Giao diá»‡n Open WebUI cÃ³ khÃ¡ nhiá»u chá»©c nÄƒng nhÆ° quáº£n lÃ½ model, quáº£n lÃ½ user (náº¿u báº¡n lÃ  admin), quáº£n lÃ½ database... NgoÃ i ra cÃ³ cáº£ má»™t sá»‘ tÃ­nh nÄƒng nÃ¢ng cao nhÆ° káº¿t ná»‘i vá»›i image generator vá»›i ComfyUI hay A1111.

TrÃªn Ä‘Ã¢y lÃ  bÃ i viáº¿t hÆ°á»›ng dáº«n sÆ¡ lÆ°á»£c vá» cÃ¡ch dá»±ng nhanh má»™t chatbot Ä‘á»ƒ thá»­ nghiá»‡m cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n. Hy vá»ng nÃ³ giÃºp Ã­ch cho project cá»§a cÃ¡c báº¡n. MÃ¬nh sáº½ cá»‘ gáº¯ng nghiÃªn cá»©u vÃ  ra nhiá»u bÃ i viáº¿t chuyÃªn sÃ¢u hÆ¡n trong lÄ©nh vá»±c Generative AI trong tÆ°Æ¡ng lai ğŸ˜Š
